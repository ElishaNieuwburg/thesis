{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHSWJt68dS_D"
      },
      "source": [
        "## Full notebook for running a YOLOv5 training and creating Eigen-CAM visualizations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2wLlPXVKddrN"
      },
      "source": [
        "### Import all code from respository\n",
        "\n",
        "Download the code, install all requirements in requirements.txt and structure it that tutorial is inside the main folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKEW4bwpLZT8"
      },
      "source": [
        "### YOLOv5 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vV-pe-vLXLS",
        "outputId": "a6694d24-773f-4d27-a6cb-0832951b8b83"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceRnxaYLdhFW"
      },
      "source": [
        "### Custom YOLOv5 training\n",
        "\n",
        "Comment out when you want to train your own YOLOv5 model.\n",
        "Follow the tutorial of https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqvdMEAOMbJr"
      },
      "outputs": [],
      "source": [
        "## Use this code if your data is located on Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2I5BLe6LNJ5"
      },
      "outputs": [],
      "source": [
        "## Change data path to path where yaml file is located\n",
        "# !python yolov5/train.py --batch-size 64 --epochs 1 --data '/content/gdrive//MyDrive/data/DamageNT/damage.yaml' --weights 'yolov5/yolov5s.pt' --hyp 'yolov5/data/hyps/hyp.no-augmentation.yaml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z-nfmSTPSjh"
      },
      "outputs": [],
      "source": [
        "## Automatically uses best weights obtained from training in previous cell\n",
        "## Also change here data to own data path!\n",
        "# !python yolov5/val.py --weights yolov5/runs/train/exp/weights/best.pt --data '/content/gdrive//MyDrive/data/DamageNT/damage.yaml' --task test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVqhVIrfMwmc"
      },
      "source": [
        "### YOLOv5 inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "GvwlYMD069_F",
        "outputId": "cf525aff-7cdf-4842-fa9e-07f584270977"
      },
      "outputs": [],
      "source": [
        "# You can use the pretrained weights from the repository, or weights from own training\n",
        "# Test images are provided in data folder\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/yolov5s.pt')\n",
        "img = \"data/images/test_img_1.png\"\n",
        "results = model(img)\n",
        "results.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjdCJ7pkdlGb"
      },
      "source": [
        "## Eigen-CAM visualizations\n",
        "#### Code based on the tutorial of https://jacobgil.github.io/pytorch-gradcam-book/EigenCAM%20for%20YOLO5.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBUWB2nadny0",
        "outputId": "5d3f5444-64d6-42fe-df76-04d4b55e85c5"
      },
      "outputs": [],
      "source": [
        "!pip install grad-cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1akWrgIRKlc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "CODE TAKEN FROM https://jacobgil.github.io/pytorch-gradcam-book/EigenCAM%20for%20YOLO5.html\n",
        "\"\"\"\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "import torch    \n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_grad_cam import EigenCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, scale_cam_image\n",
        "from PIL import Image\n",
        "\n",
        "COLORS = np.random.uniform(0, 255, size=(80, 3))\n",
        "\n",
        "# Get the YOLOv5 detections\n",
        "def parse_detections(results):\n",
        "    detections = results.pandas().xyxy[0]\n",
        "    detections = detections.to_dict()\n",
        "    boxes, colors, names = [], [], []\n",
        "\n",
        "    for i in range(len(detections[\"xmin\"])):\n",
        "        confidence = detections[\"confidence\"][i]\n",
        "        if confidence < 0:\n",
        "            continue\n",
        "        xmin = int(detections[\"xmin\"][i])\n",
        "        ymin = int(detections[\"ymin\"][i])\n",
        "        xmax = int(detections[\"xmax\"][i])\n",
        "        ymax = int(detections[\"ymax\"][i])\n",
        "        name = detections[\"name\"][i]\n",
        "        category = int(detections[\"class\"][i])\n",
        "        color = COLORS[category]\n",
        "\n",
        "        boxes.append((xmin, ymin, xmax, ymax))\n",
        "        colors.append(color)\n",
        "        names.append(name)\n",
        "    return boxes, colors, names\n",
        "\n",
        "\n",
        "# Draw detections on the image\n",
        "def draw_detections(boxes, colors, img):\n",
        "    for box, color in zip(boxes, colors):\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), color, 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "def renormalize_cam_in_bounding_boxes(boxes, colors, image_float_np, grayscale_cam):\n",
        "    \"\"\"Normalize the CAM to be in the range [0, 1] \n",
        "    inside every bounding boxes, and zero outside of the bounding boxes. \"\"\"\n",
        "    renormalized_cam = np.zeros(grayscale_cam.shape, dtype=np.float32)\n",
        "    for x1, y1, x2, y2 in boxes:\n",
        "        renormalized_cam[y1:y2, x1:x2] = scale_cam_image(grayscale_cam[y1:y2, x1:x2].copy())    \n",
        "    renormalized_cam = scale_cam_image(renormalized_cam)\n",
        "    eigencam_image_renormalized = show_cam_on_image(image_float_np, renormalized_cam, use_rgb=True)\n",
        "    image_with_bounding_boxes = draw_detections(boxes, colors, eigencam_image_renormalized)\n",
        "    return image_with_bounding_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxpucY88R1Kt"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLcCwG9QRxMC"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Change the YOLO format boxes to VOC format\n",
        "def yolo_to_voc(boxes, size):\n",
        "    non_centred_box = boxes[:, :2] - 0.5 * boxes[:, 2:]\n",
        "    boxes = np.concatenate((non_centred_box, non_centred_box + boxes[:, 2:]), axis=1)\n",
        "    boxes[:, [0, 2]] *= size[0]\n",
        "    boxes[:, [1, 3]] *= size[1]\n",
        "\n",
        "    # Scale boxes to width and height of image\n",
        "    boxes[boxes < 0] = 0\n",
        "    boxes[:, 0][boxes[:, 0] > size[0]] = size[0]\n",
        "    boxes[:, 1][boxes[:, 1] > size[1]] = size[1]\n",
        "    boxes[:, 2][boxes[:, 2] > size[0]] = size[0]\n",
        "    boxes[:, 3][boxes[:, 3] > size[1]] = size[1]\n",
        "\n",
        "    return boxes\n",
        "\n",
        "\n",
        "# Compute the Intersection over Union score between two boxes\n",
        "def iou(gt_box, pred_box):\n",
        "    area =  max(0, min(gt_box[2], pred_box[2]) - max(gt_box[0], pred_box[0]) + 1) * \\\n",
        "            max(0, min(gt_box[3], pred_box[3]) - max(gt_box[1], pred_box[1]) + 1)\n",
        "\n",
        "    gt_area = (gt_box[2] - gt_box[0] + 1) * (gt_box[3] - gt_box[1] + 1)\n",
        "    pred_area = (pred_box[2] - pred_box[0] + 1) * (pred_box[3] - pred_box[1] + 1)\n",
        "\n",
        "    return area / float(gt_area + pred_area - area)\n",
        "\n",
        "# Crop the image given a certain scale\n",
        "def crop_img(img, scale):\n",
        "    w, h = img.size\n",
        "    new_w = w / scale\n",
        "    new_h = h / scale\n",
        "    left = (w - new_w) / scale\n",
        "    right = new_w + (w - new_w) / scale\n",
        "    top = (h - new_h) / scale\n",
        "    bottom = new_h + (h - new_h) / scale\n",
        "\n",
        "    return img.crop((left, top, right, bottom))\n",
        "\n",
        "\n",
        "# Resize a bounding box given a new size of the image\n",
        "def resize_box(boxes, size_new, size_old):\n",
        "    x_scale = size_new[0] / size_old[0]\n",
        "    y_scale = size_new[1] / size_old[1]\n",
        "    \n",
        "    left = int(boxes[:, 0] * x_scale)\n",
        "    top = int(boxes[:, 1] * y_scale)\n",
        "    right = int(boxes[:, 2] * x_scale)\n",
        "    bottom = int(boxes[:, 3] * y_scale)\n",
        "    \n",
        "    return left, top, right, bottom\n",
        "\n",
        "\n",
        "# Blacken an image around a bounding box area\n",
        "def black_img(img, box):\n",
        "    img[:, :box[0]] = 0\n",
        "    img[:box[1], :] = 0\n",
        "    img[:, box[2]:] = 0\n",
        "    img[box[3]:, :] = 0\n",
        "    \n",
        "    return img\n",
        "\n",
        "# Compute false positives and false negatives\n",
        "def get_fp_fn(boxes, gt_boxes, colors):\n",
        "    matches = defaultdict(list)\n",
        "    fp = len(boxes)\n",
        "    fn = len(gt_boxes)\n",
        "    for i, box in enumerate(gt_boxes):\n",
        "        for j, pred_box in enumerate(boxes):\n",
        "            if iou(box, pred_box) > 0.45:\n",
        "                matches[i] = pred_box\n",
        "                fp -= 1\n",
        "                fn -= 1\n",
        "                colors[j] = (0, 255, 0)\n",
        "\n",
        "    return fp, fn, matches, colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDN4G_qER7ZY"
      },
      "outputs": [],
      "source": [
        "# Create the Eigen-CAM visualizations\n",
        "def create_vis(array_img, img_name, label_path):\n",
        "    # Prepare image\n",
        "    img = cv2.resize(array_img, (640, 640))\n",
        "    rgb_img = img.copy()\n",
        "    img = np.float32(img) / 255\n",
        "    transform = transforms.ToTensor()\n",
        "    tensor = transform(img).unsqueeze(0)\n",
        "    \n",
        "    # Get detections on image\n",
        "    results = model([rgb_img.copy()])\n",
        "    boxes, colors, names = parse_detections(results)  # Boxes are xmin, ymin, xmax, ymax, (not normalized) confidence, class, name\n",
        "    colors = [(255, 0, 0) for _ in range(len(boxes))]\n",
        "    \n",
        "    try:\n",
        "        f = open(os.path.join(label_path, img_name[:-4] + '.txt'), 'r')\n",
        "        data = np.array([line.strip().split(\" \") for line in f.readlines()]).astype(float)\n",
        "        f.close()\n",
        "    except OSError:\n",
        "        gt_boxes = []\n",
        "        detections = rgb_img.copy()\n",
        "    else:\n",
        "        gt_boxes = yolo_to_voc(data[:, 1:], (img.shape[1], img.shape[0]))\n",
        "        detections = draw_detections(gt_boxes, [(0, 0, 255) for _ in range(len(gt_boxes))], rgb_img.copy())\n",
        "\n",
        "    # If you want to know what the false positives, true positives are\n",
        "    _, _, _, colors = get_fp_fn(boxes, gt_boxes, colors)\n",
        "    \n",
        "    cam = EigenCAM(model, target_layers, use_cuda=False)\n",
        "    grayscale_cam = cam(tensor)[0, :, :]\n",
        "    cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
        "    drawn_cam_image = draw_detections(boxes, colors, cam_image.copy())\n",
        "    renormalized_cam_image = renormalize_cam_in_bounding_boxes(boxes, colors, img, grayscale_cam)\n",
        "    im = Image.fromarray(np.hstack((cv2.resize(detections, (586, 371)), cv2.resize(cam_image, (586, 371)), cv2.resize(renormalized_cam_image, (586, 371)))))\n",
        "        \n",
        "    return im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcLX-Sl0SQOi"
      },
      "outputs": [],
      "source": [
        "# File paths, change to custom data paths if necessary\n",
        "imgs_path = 'data/images'\n",
        "label_path = 'data/labels'\n",
        "weights_path = 'weights/yolov5s.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QGeZFO8SMb-",
        "outputId": "54678e88-f93f-453a-8ef4-1529622c6143"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)\n",
        "model.eval()\n",
        "model.cpu()\n",
        "target_layers = [model.model.model.model[-2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "tZ9JI7hKSSCv",
        "outputId": "f6f5fa10-5ef9-4c48-d7e8-3becd04d4953"
      },
      "outputs": [],
      "source": [
        "# Run on a test image and save\n",
        "img_name =  'test_img_2.png'\n",
        "output_name = 'test_img_cam.png'\n",
        "img = np.array(Image.open(os.path.join(imgs_path, img_name)))\n",
        "cam_im = create_vis(img, img_name, label_path)\n",
        "cam_im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
